{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b19fff-8f42-4e9f-a73e-00cff106805a",
   "metadata": {},
   "source": [
    "# M-Shots Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34723a72-1601-4685-a0ba-bff544425d48",
   "metadata": {
    "id": "34723a72-1601-4685-a0ba-bff544425d48"
   },
   "source": [
    "In this notebook, we'll explore small prompt engineering techniques and recommendations that will help us elicit responses from the models that are better suited to our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba193cc-d8a0-4ad2-8177-380204426859",
   "metadata": {
    "id": "fba193cc-d8a0-4ad2-8177-380204426859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "# check get key\n",
    "if OPENAI_API_KEY:\n",
    "    print(\"API key loaded successfully\")\n",
    "else:\n",
    "    print(\"API key NOT found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502cfc93-21e0-498f-9650-37bc6ddd514d",
   "metadata": {
    "id": "502cfc93-21e0-498f-9650-37bc6ddd514d"
   },
   "source": [
    "# Formatting the answer with Few Shot Samples.\n",
    "\n",
    "To obtain the model's response in a specific format, we have various options, but one of the most convenient is to use Few-Shot Samples. This involves presenting the model with pairs of user queries and example responses.\n",
    "\n",
    "Large models like GPT-3.5 respond well to the examples provided, adapting their response to the specified format.\n",
    "\n",
    "Depending on the number of examples given, this technique can be referred to as:\n",
    "* Zero-Shot.\n",
    "* One-Shot.\n",
    "* Few-Shots.\n",
    "\n",
    "With One Shot should be enough, and it is recommended to use a maximum of six shots. It's important to remember that this information is passed in each query and occupies space in the input prompt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8344712-06d7-4c24-83d8-f36d62926e5e",
   "metadata": {
    "id": "a8344712-06d7-4c24-83d8-f36d62926e5e"
   },
   "outputs": [],
   "source": [
    "# Function to call the model.\n",
    "def return_OAIResponse(user_message, context):\n",
    "    client = OpenAI() \n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=1,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f611d73d-9330-466d-b705-543667e1b561",
   "metadata": {
    "id": "f611d73d-9330-466d-b705-543667e1b561"
   },
   "source": [
    "In this zero-shots prompt we obtain a correct response, but without formatting, as the model incorporates the information he wants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "647790be-fdb8-4692-a82e-7e3a0220f72a",
    "outputId": "4c4a9f4f-67c9-4a11-837f-1a1fd6b516ff"
   },
   "outputs": [],
   "source": [
    "#zero-shot\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are an expert in F1.'}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2010?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a9a0a-c1b9-4759-b52f-f6547d29b4c8",
   "metadata": {
    "id": "e87a9a0a-c1b9-4759-b52f-f6547d29b4c8"
   },
   "source": [
    "For a model as large and good as GPT 3.5, a single shot is enough to learn the output format we expect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33ac7693-6cf3-44f7-b2ff-55d8a36fe775",
    "outputId": "5278df23-8797-4dc2-9340-ac29c1318a9c"
   },
   "outputs": [],
   "source": [
    "#one-shot\n",
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in F1.\n",
    "\n",
    "     Who won the 2000 f1 championship?\n",
    "     Driver: Michael Schumacher.\n",
    "     Team: Ferrari.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2011?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c454a8-181b-482b-873a-81d6ffde4674",
   "metadata": {
    "id": "32c454a8-181b-482b-873a-81d6ffde4674"
   },
   "source": [
    "Smaller models, or more complicated formats, may require more than one shot. Here a sample with two shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ce600f7-f92e-4cf7-be4a-408f12eb39d6",
    "outputId": "a6f90f5d-6d68-4b3d-ccb5-5848ae4e3e62"
   },
   "outputs": [],
   "source": [
    "#Few shots\n",
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in F1.\n",
    "\n",
    "     Who won the 2010 f1 championship?\n",
    "     Driver: Sebastian Vettel.\n",
    "     Team: Red Bull Renault.\n",
    "\n",
    "     Who won the 2009 f1 championship?\n",
    "     Driver: Jenson Button.\n",
    "     Team: BrawnGP.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b29898a-f715-46d4-b74b-9f95d3112d38",
    "outputId": "75f63fe3-0efc-45ed-dd45-71dbbb08d7a6"
   },
   "outputs": [],
   "source": [
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86",
   "metadata": {
    "id": "5f1b71c4-6583-4dcb-b987-02abf6aa4a86"
   },
   "source": [
    "We've been creating the prompt without using OpenAI's roles, and as we've seen, it worked correctly.\n",
    "\n",
    "However, the proper way to do this is by using these roles to construct the prompt, making the model's learning process even more effective.\n",
    "\n",
    "By not feeding it the entire prompt as if they were system commands, we enable the model to learn from a conversation, which is more realistic for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20fa4a25-01a6-4f22-98db-ab7ccc9ba115",
    "outputId": "868d2040-ca3c-4a47-a1e8-1e08d581191d"
   },
   "outputs": [],
   "source": [
    "#Recomended solution\n",
    "context_user = [\n",
    "    {'role':'system', 'content':'You are and expert in f1.\\n\\n'},\n",
    "    {'role':'user', 'content':'Who won the 2010 f1 championship?'},\n",
    "    {'role':'assistant', 'content':\"\"\"Driver: Sebastian Vettel. \\nTeam: Red Bull. \\nPoints: 256. \"\"\"},\n",
    "    {'role':'user', 'content':'Who won the 2009 f1 championship?'},\n",
    "    {'role':'assistant', 'content':\"\"\"Driver: Jenson Button. \\nTeam: BrawnGP. \\nPoints: 95. \"\"\"},\n",
    "]\n",
    "\n",
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f6b42-f351-496b-a7e8-1286426457eb",
   "metadata": {
    "id": "ac6f6b42-f351-496b-a7e8-1286426457eb"
   },
   "source": [
    "We could also address it by using a more conventional prompt, describing what we want and how we want the format.\n",
    "\n",
    "However, it's essential to understand that in this case, the model is following instructions, whereas in the case of use shots, it is learning in real-time during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36c32a32-c348-45b2-85ee-ab4500438c49",
    "outputId": "4c970dde-37ff-41a9-8d4e-37bb727f47a6"
   },
   "outputs": [],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\"\"\"You are and expert in f1.\n",
    "    You are going to answer the question of the user giving the name of the rider,\n",
    "    the name of the team and the points of the champion, following the format:\n",
    "    Drive:\n",
    "    Team:\n",
    "    Points: \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KNDL1GzVngyL",
   "metadata": {
    "id": "KNDL1GzVngyL"
   },
   "outputs": [],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are classifying .\n",
    "\n",
    "     Who won the 2010 f1 championship?\n",
    "     Driver: Sebastian Vettel.\n",
    "     Team: Red Bull Renault.\n",
    "\n",
    "     Who won the 2009 f1 championship?\n",
    "     Driver: Jenson Button.\n",
    "     Team: BrawnGP.\"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qZPNTLMPnkQ4",
   "metadata": {
    "id": "qZPNTLMPnkQ4"
   },
   "source": [
    "Few Shots for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ejcstgTxnnX5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejcstgTxnnX5",
    "outputId": "4b91cc73-18f6-4944-a46b-806b02b7becb"
   },
   "outputs": [],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':\n",
    "     \"\"\"You are an expert in reviewing product opinions and classifying them as positive or negative.\n",
    "\n",
    "     It fulfilled its function perfectly, I think the price is fair, I would buy it again.\n",
    "     Sentiment: Positive\n",
    "\n",
    "     It didn't work bad, but I wouldn't buy it again, maybe it's a bit expensive for what it does.\n",
    "     Sentiment: Negative.\n",
    "\n",
    "     I wouldn't know what to say, my son uses it, but he doesn't love it.\n",
    "     Sentiment: Neutral\n",
    "     \"\"\"}\n",
    "]\n",
    "print(return_OAIResponse(\"I'm not going to return it, but I don't plan to buy it again.\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe1d50b-d262-4e74-8f2d-3559f3fcfb15",
   "metadata": {
    "id": "ZHr_75sDqDJp"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ec6fee",
   "metadata": {},
   "source": [
    "0 shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "921d76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':'You are chatgpt 3.5.'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9adda59c-ad09-4e9d-88cd-54f42384a5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"mspzz wth nn s grt\"\n"
     ]
    }
   ],
   "source": [
    "print(return_OAIResponse(\"Remove the vowels from my sentence: mississippi pizza with ananas is great\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42be5ac0",
   "metadata": {},
   "source": [
    "1 - shot. Only 1 example. No system instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5728c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_user = [\n",
    "    {'role':'system', 'content':'You are chatgpt 3.5.'},\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Remove the vowels from Hello World'\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "        'content': 'hll wrld'\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876d35a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mssssppzz wth nnns s grt\n"
     ]
    }
   ],
   "source": [
    "print(return_OAIResponse(\"Remove the vowels from my sentence: mississippi pizza with ananas is great\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea9c39",
   "metadata": {},
   "source": [
    "1 - shot. Only instructions. No examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae1eabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_user = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': \"\"\"You apply the Vowel Collapse Cipher.\n",
    "\n",
    "Rules:\n",
    "- Remove all vowels (a, e, i, o, u).\n",
    "- Keep consonants in original order.\n",
    "- Keep spaces.\n",
    "- Output must be lowercase.\n",
    "- Do not include punctuation.\n",
    "- Return ONLY the transformed sentence.\n",
    "\"\"\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bacb30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msspp pz wz nnns s grt\n"
     ]
    }
   ],
   "source": [
    "print(return_OAIResponse(\"Remove the vowels from my sentence: mississippi pizza with ananas is great\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383a31d9",
   "metadata": {},
   "source": [
    "2 shot. Instructions and 2 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fd615f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_user = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': \"\"\"You apply the Vowel Collapse Cipher.\n",
    "\n",
    "Rules:\n",
    "- Remove all vowels (a, e, i, o, u).\n",
    "- Keep consonants in original order.\n",
    "- Keep spaces.\n",
    "- Output must be lowercase.\n",
    "- Do not include punctuation.\n",
    "- Return ONLY the transformed sentence.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Hello World'\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "        'content': 'hll wrld'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'I love pizza'\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "        'content': 'lv pzz'\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a5d3b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msssspp pz wz nnns s grt\n"
     ]
    }
   ],
   "source": [
    "print(return_OAIResponse(\"Remove the vowels from my sentence: mississippi pizza with ananas is great\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa37e0f",
   "metadata": {},
   "source": [
    "3 shot with exact example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10b7cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_user = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': \"\"\"You apply the Vowel Collapse Cipher.\n",
    "\n",
    "Rules:\n",
    "- Remove all vowels (a, e, i, o, u).\n",
    "- Keep consonants in original order.\n",
    "- Keep spaces.\n",
    "- Output must be lowercase.\n",
    "- Do not include punctuation.\n",
    "- Return ONLY the transformed sentence.\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Hello World'\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "        'content': 'hll wrld'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'I love pizza'\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "        'content': 'lv pzz'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'mississippi pizza with ananas is great'\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "        'content': 'msssspp pzz wth nns s grt'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c111a691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msssspp pzz wth nns s grt\n"
     ]
    }
   ],
   "source": [
    "print(return_OAIResponse(\"Remove the vowels from my sentence: mississippi pizza with ananas is great\", context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5bc34",
   "metadata": {},
   "source": [
    "Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ea3efb",
   "metadata": {},
   "source": [
    "From the experiments, we observe that GPT-3.5 can handle simple rule-based transformations reasonably well in a zero-shot setting when the instruction is explicit and concrete (e.g., “remove the vowels”). However, even in this relatively simple task, small inconsistencies can appear: spacing issues, minor formatting deviations, or subtle differences in how strictly the model interprets the rule. This shows that while GPT-3.5 has strong pattern-recognition capabilities, its adherence to precise procedural constraints is not always perfectly stable without additional grounding.\n",
    "\n",
    "When we move to one-shot and two-shot prompting, the model’s behavior becomes more consistent and predictable. Providing examples reduces ambiguity about the expected transformation pattern and output format. With two examples in particular, GPT-3.5 generalizes the rule more reliably and minimizes small structural errors. The key learning is that few-shot prompting does not necessarily teach the model new knowledge, but it significantly improves rule alignment, output consistency, and compliance with formatting constraints. In structured or symbolic tasks, additional examples act as anchors that stabilize the model’s interpretation of the instructions."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
